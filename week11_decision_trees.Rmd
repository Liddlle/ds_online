---
title: "Week11_final"
output: html_document
---

 Предположим, перед вами стоят следующие задачи:

* есть растения нескольких сортов, нужно выделить признаки, характеризующие каждый сорт
* есть ряд диагнозов, необходимо определить симптомы, соответствующие диагнозу
* есть база клиентов с указанием, кто продолжает пользоваться сервисоами компании, а кто ушел. Нужно выделить признаки, которые позволят выявить "проблемных" клиентов

Подобные задачи делятся на две групы: задачи регрессии и задачи классификации. Задача классификации возникает  в том случае, если интересующим нас показателем является принадлежность в некоторому классу (болен/не болен, спам/не спам, ушел/остался, высокий/средний/низкий...) -- т.е. категориальная переменная. 

Про задачу регрессии мы говорим тогда, когда мы хотим предсказать некий количественный, числовой показатель (уровень продаж, рейтинг, риск заразиться...).

Рассмотрим, как подобные задачи можно решать с помощью R.

Первый датасет, с которым мы будем работать содержит данные о пассажирах Титаника. О датасете https://www.kaggle.com/c/titanic/data
Когда Титаник затонул, 1502 из 2224 пассажиров и членов экипажа погибли. Одна из главных причин такого большого числа жертв - нехватка спасательных жилетов на корабле. Те, кто смотрел фильм, знают, что шанс некоторых пассажиров выжить был больше (Роуз), чем других (бедный Джек). Далее мы применим техники машинного обучения для предсказания шанса выжить для каждого пассажира.

Загрузим данные и разделим их на **обучающую (train)** и **тестовую (test)** выборки. На первой вы будете строить модель, а на второй оценивать качество предсказания. Тестовая выборка будет содержать 20% данных

```{r}
titanic <- read.csv("/principal/courses/minor2_2016/lab10-tree2/Titanic.csv")
str(titanic)

titanic$Pclass <- as.factor(titanic$Pclass)
titanic$Survived <- as.factor(titanic$Survived)
```
Сначала посчитаем, сколько строк составят 20% от данных
```{r}
test_size = nrow(titanic)*0.20
test_size
```

Теперь отберем `r test_size` номеров строк случайным образом
```{r}
set.seed(1238)
test_indices = sample(1:dim(titanic)[1], test_size)
head(test_indices, 20)
```

Затем в качестве тестовой выборки возьмем те строки, номера которых "выпали"

```{r}
test_data = titanic[test_indices,]
```

А в качестве обучающей --  все, кроме них

```{r}
train_data = titanic[-test_indices,]
```
Как много людей в вашей тренировачной выборке выжили? Чтобы узнать это используйте команду table() в комбинации с $-оператором для выбора колонки из таблицы.

```{r}
# Число выживших в абсолютных числах
table(train_data$Survived)

# В пропорциях
prop.table(table(train_data$Survived))
```
Теперь видно, что  439 человек погибли (62%) и 274 выжили (38%). 

В целом, команда table() может помочь вам выявить какие переменные имеют предсказательную силу. Например, может быть пол имеет значение для предсказания? Для включения гендера в сравнение используйте следующий код

```{r}
table(train_data$Sex, train_data$Survived)
```
Для получения пропорций заверните table() в prop.table(), но нужно будет уточнить какую пропорцию вы хотите: построчную или колоночную. Для этого включите в prop.table() аргумент margin и определите его значение как 1 или 2 соответственно.
```{r}
prop.table(table(train_data$Sex, train_data$Survived), 1)
```
Еще одна переменная, которая может повлиять на выживаемость - возраст: возможно, детей спасали в первую очередь. Вы проверите это, создав категориальную переменную child. 
```{r}
# Создаем переменную
train_data$Child <- NA
train_data$Child[train_data$Age < 18] <- 1
train_data$Child[train_data$Age >= 18] <- 0

# Двусторонее сравнение
prop.table(table(train_data$Child, train_data$Survived), 1)
```
До настоящего момента вы проделали определенные манипуляции, чтобы найти сабсеты, имеющие больший шанс выжить (женщины и дети). Дерево решений автоматизирует этот процесс и в результате вы получаете блок-схему, которая легко интерпретируется. 

Концептуально алгоритм дерева решений делит исходный набор данных на подмножества, которые становятся все более и более гомогенными относительно определенных признаков, в результате чего формируется древовидная иерархическая структура. Алгоритм начинает со всех данных в корневом узле и сканирует все переменные, выбирая лучшую из них для разделения. Как только переменная выбрана, происходит разделение и переход на один уровень (или узел) ниже, далее эта процедура повторяется. Конечные узлы дерева называются терминальными (terminal nodes) или листьями (leaves).

Для построения первого дерева решений мы будем использовать пакет rpart.
Подробнее про пакет бы можете прочитать здесь https://cran.r-project.org/web/packages/rpart/rpart.pdf

```{r}
library(rpart)
```
Внутри rpart, есть функция rpart(), с помощью которой мы и построим дерево решений. Функция включает следующие аргументы:

**formula:** специфицирует интересующую переменную (Dependent variable) и переменные, используемые для предсказания (Independent variable) (например, formula = Survived ~ Sex + Age). Если хотите построить дерево, используя все переменные, то примените следующую формулу (formula = Survived ~.)
**data:** датасет для построения дерева (у нас это train_data).
**method:** тип предсказания. Мы хотим предсказать категориальную переменную, это задача классификации: method = "class".

Чтобы визуализировать полученное дерево вы можете использовать prp(my_tree) из пакета rpart.plot. 
```{r}
# Build the decision tree
my_tree <- rpart(Survived ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked, data = train_data, method = "class")

# Визуализируем дерево решений
library(rpart.plot)
prp(my_tree)

# Добавим больше информативности
prp(my_tree, type=2, extra=104)
prp(my_tree, type=2, extra=104, nn=TRUE, fallen.leaves=TRUE,faclen=0, varlen=0, shadow.col="grey", branch.lty=3)
```
Каждый терминальный узел помечен предсказанным классом. Все они размещены внизу дерева (fallen.leaves=TRUE), чтобы визуально усилить структуру. Мы видим прямые линии сверху вниз, что позволяет быстро принять решение, в то время как более сложные пути требуют больше времени для принятия решения. Каждый узел содержит вероятность для каждого класса, процент наблюдений ассоциируемый с узлом (extra=104). Включены номера узлов (nn=TRUE), это позволяет перекрестно ссылаться на каждый узел дерева. Использование тип пунктирной линии (branch.lty=3) переключает внимание с тяжелых линий и фокусирует его на узлах, при этом все еще четко можно проследить связи. Серая тень - приятное дополнение.

Множество способов визуализации с помощью prp() описано здесь http://www.academia.edu/6241482/Data_Science_with_R_Decision_Trees

Основываясь на построенном дереве решений определите, какие переменные играют наибольшую роль в определении того выживет ли пассажир?

**Варианты ответа**
Sex, Age, Pclass, SibSp, Parch, Fare and Embarked
Sex, Age, Pclass, SibSp, Embarked, Fare - верный
Sex, Age, Parch and Embarked
Sex, Age and Embarked

Следующим шагом нам нужно предсказать количество выживших для наблюдений в тестовой выборке. Для этого мы воспользуемся функцией predict(). Здесь, my_tree это модель, которую вы построили, test_data это датасет, для которого вы делаете предсказания
```{r}
my_prediction <- predict(my_two, newdata = test_data, type = "class")
my_prediction

table(my_prediction, test_data$Survived) ##confusion table
(100+42)/178
```
Точность модели - 80%

Давайте попробуем улучшить этот показатель, добавив family_size. Предположение заключается в том, что большим семьям требуется больше времени чтобы собраться вместе на тонущем корабле, соответвтвенно у них шанс выжить меньше. Размер семьи определяется переменными SibSp и Parch, которые отражают количество членов семьи, с которыми путешествует каждый конкретный пассажир. Для создания новой переменной family_size, мы суммируем SibSp и Parch плюс один (само наблюдение).
```{r}
train_data$family_size <- train_data$SibSp + train_data$Parch + 1
test_data$family_size <- test_data$SibSp + test_data$Parch + 1

my_tree_three <- rpart(Survived ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked + family_size,
                      data = train_data, 
                      method = "class")
prp(my_tree_three)

my_prediction2 <- predict(my_tree_three, newdata = test_data, type = "class")
my_prediction2

table(my_prediction2, test_data$Survived) ##confusion table
(104+42)/178
```
Точность 82% - качество предсказания улучшилось.

Мы можем улучшить этот показатель, сделав модель более сложной. В rpart количество деталей опредлеляется двумя параметрами:

**cp**(complexity parameter) - это метрика, которая останавливает ветвление дерева, когда оно уже не улучшает показатели модели. 
**minsplit** определяет минимальное количество наблюдений, которые должны содержаться в листе дерева

```{r}
# Построим дерево с минимальным количество наблюдений в каждом листе 5 и с cp = 0.006
my_tree_four <- rpart(Survived ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked, data = train_data, method = "class", control = rpart.control(minsplit = 5, cp = 0.006))

# Визуализируем
prp(my_tree_four)
```
Таким образом мы постороили дерево классификации. Для построение дерева регрессии с помощью rpart требуется tree pruning - отсечение ветвей там, где эта процедура не приводит к серьезному возрастанию ошибки. Подробнее читайте здесь http://r-analytics.blogspot.ru/2017/02/blog-post.html#.WZBlq-zyjIV

Для построения regression decision tree мы будем использовать другой датасет и пакет partykit 
https://cran.r-project.org/web/packages/partykit/partykit.pdf



В следующей статье сравниваются фукции rpart() из пакета rpart и ctree() из пакета party https://www.r-bloggers.com/party-with-the-first-tribe/